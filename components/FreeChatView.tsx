import React, { useEffect, useState, useRef } from 'react';
import { View, Text, Image, FlatList, TouchableOpacity, StyleSheet } from 'react-native';
import * as Speech from 'expo-speech';
import { fetchGptResponse } from '../services/fetchGptResponse';
import { generateFreeTalkFeedback, saveFeedbackToStorage } from '../utils/feedback';
import { useLanguage } from '../hooks/useLanguage';
import { useFeedbackStore } from '../store/feedbackStore';
import type { Message, FeedbackItem, DialogState, LanguageCode, PracticeScene, TopicType, LevelType } from '../types';
import { usePersistentChatHistory } from '../context/PersistentChatHistoryContext';

const feedbackTranslations = {
  en: {
    saved: 'Your feedback has been saved!',
    saveError: 'Failed to save feedback data.',
    noErrors: 'No significant errors found.',
    processError: 'An error occurred during feedback processing.'
  },
  ko: {
    saved: 'í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!',
    saveError: 'í”¼ë“œë°± ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
    noErrors: 'ì¤‘ìš”í•œ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
    processError: 'í”¼ë“œë°± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
  },
  ja: {
    saved: 'ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸï¼',
    saveError: 'ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚',
    noErrors: 'é‡å¤§ãªã‚¨ãƒ©ãƒ¼ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚',
    processError: 'ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚'
  },
  zh: {
    saved: 'åé¦ˆå·²ä¿å­˜ï¼',
    saveError: 'ä¿å­˜åé¦ˆæ•°æ®å¤±è´¥ã€‚',
    noErrors: 'æœªå‘ç°æ˜æ˜¾é”™è¯¯ã€‚',
    processError: 'åé¦ˆå¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ã€‚'
  }
};

type FreeChatViewProps = {
  topicKey: string;
  messages: Message[];
  addMessage: (
    topic: string,
    role: 'user' | 'ai',
    text: string,
    metadata?: Message['metadata'],
  ) => void;
  startRecording: () => void;
  stopRecording: () => void;
  isRecording: boolean;
  transcript: string;
  clearTranscript: () => void;
  onExitFreeTalk: () => void;
};

export default function FreeChatView({
  topicKey,
  messages,
  addMessage,
  startRecording,
  stopRecording,
  isRecording,
  transcript,
  clearTranscript,
  onExitFreeTalk,
}: FreeChatViewProps) {
  const [localMessages, setLocalMessages] = useState(messages ?? []);
  const [feedbackMessage, setFeedbackMessage] = useState<{ type: string; text: string } | null>(null);
  const { language } = useLanguage();
  const isCancelledRef = useRef(false);
  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);
  const noResponseTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const NO_RESPONSE_TIMEOUT = 10000; // 10ì´ˆ ë¬´ì‘ë‹µ ì‹œ ì•ˆë‚´ ë©”ì‹œì§€
  const flatListRef = useRef<FlatList>(null);
  const [speakingIndex, setSpeakingIndex] = useState(-1); // í˜„ì¬ ë§í•˜ê³  ìˆëŠ” index
  const [currentSpeakingText, setCurrentSpeakingText] = useState<string[]>([]);
  const [speakingWordIndex, setSpeakingWordIndex] = useState(-1); // <- í…ìŠ¤íŠ¸ ë‹¨ìœ„ í•˜ì´ë¼ì´íŠ¸ìš©

  const scrollToIndex = (index: number) => {
     requestAnimationFrame(() => {
       flatListRef.current?.scrollToIndex({ index, animated: true });
     });
  };

  const splitIntoWords = (text: string) => {
     return text.trim().split(/(\s+)/); // ê³µë°± í¬í•¨í•´ì„œ splití•´ì„œ ì›ë¬¸ ìœ ì§€
  };

  useEffect(() => {
    // ì´ˆê¸°í™” ì‹œ ìë™ ë…¹ìŒ ì‹œì‘
    startAutoRecording();
    return () => {
      isCancelledRef.current = true;
      clearTimers();
    };
  }, []);

  useEffect(() => {
     // ë©”ì‹œì§€ê°€ ì—…ë°ì´íŠ¸ë  ë•Œë§ˆë‹¤ ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤
     if (flatListRef.current) {
       flatListRef.current.scrollToEnd({ animated: true });
     }
  }, [localMessages]);

  useEffect(() => {
    if (transcript) {
      clearTimeout(noResponseTimerRef.current ?? undefined);
      processUserInput();
    }
  }, [transcript]);

  // ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
     if (flatListRef.current) {
       flatListRef.current.scrollToEnd({ animated: true });
     }
  }, [localMessages]);

  const clearTimers = () => {
    clearTimeout(silenceTimerRef.current ?? undefined);
    clearTimeout(noResponseTimerRef.current ?? undefined);
  };

  const startAutoRecording = async () => {
    if (isCancelledRef.current) return; // ğŸ”´ Stop ìƒíƒœì¼ ë•ŒëŠ” ìë™ë…¹ìŒ ì‹œì‘ ì•ˆí•¨

    clearTimers();
    startRecording();
    // ë¬´ì‘ë‹µ íƒ€ì´ë¨¸ ì‹œì‘
    noResponseTimerRef.current = setTimeout(() => {
      if (!isCancelledRef.current && !transcript) {
        handleNoResponse();
      }
    }, NO_RESPONSE_TIMEOUT);
  };

  // âœ… ë§í•˜ê¸° í•¨ìˆ˜ì—ì„œ í…ìŠ¤íŠ¸ë³„ í•˜ì´ë¼ì´íŠ¸ ì ìš©
  const speakWordByWord = (text: string, onComplete: () => void) => {
     const words = splitIntoWords(text);
     setCurrentSpeakingText(words);

     const speakNext = (idx: number) => {
       if (idx >= words.length || isCancelledRef.current) {
         setSpeakingWordIndex(-1);
         onComplete?.();
         return;
       }

       setSpeakingWordIndex(idx);

       Speech.speak(words[idx], {
         language,
         rate: 1.0,
         onDone: () => speakNext(idx + 1),
       });
     };

     speakNext(0);
  };

  const handleNoResponse = async () => {
    const promptMsg: Message = {
      id: Date.now().toString(),
      role: 'ai',
      text: language === 'en'
        ? "I didn't hear your response. Please say something to continue our conversation."
        : language === 'ko'
        ? "ë‹µë³€ì„ ë“£ì§€ ëª»í–ˆì–´ìš”. ëŒ€í™”ë¥¼ ê³„ì†í•˜ë ¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”."
        : language === 'ja'
        ? "è¿”äº‹ãŒèã“ãˆã¾ã›ã‚“ã§ã—ãŸã€‚ä¼šè©±ã‚’ç¶šã‘ã‚‹ã«ã¯ä½•ã‹è©±ã—ã¦ãã ã•ã„ã€‚"
        : "æˆ‘æ²¡æœ‰å¬åˆ°æ‚¨çš„å›å¤ã€‚è¯·è¯´äº›ä»€ä¹ˆä»¥ç»§ç»­æˆ‘ä»¬çš„å¯¹è¯ã€‚",
      timestamp: Date.now(), // âœ… ì´ì œ ì •ìƒ
    };
    
    setLocalMessages((prev: Message[]) => [...prev, promptMsg]);
    await Speech.speak(promptMsg.text, { language });
    startAutoRecording(); // ë‹¤ì‹œ ë…¹ìŒ ì‹œì‘
  };

  const exitPhrases = [
     'ì˜¤ëŠ˜ì€ ê·¸ë§Œí•˜ì', 'ëë‚´ì', 'ì¡°ê¸ˆ ìˆë‹¤ê°€ ë‹¤ì‹œí•˜ì',
     'ë‚˜ì¤‘ì— í•˜ì', 'ì´ë”° í•˜ì', 'stop', 'exit', 'let\'s stop', 'i want to stop'
  ];

  const processUserInput = async () => {
     if (!transcript || transcript.trim().length === 0) return;

     const normalizedText = transcript.trim().toLowerCase();

     // ğŸ”Š 1. ì‚¬ìš©ìê°€ ìŒì„±ìœ¼ë¡œ ì¢…ë£Œ ì˜ì‚¬ë¥¼ í‘œí˜„í•œ ê²½ìš°
     if (exitPhrases.some(phrase => normalizedText.includes(phrase))) {
        setLocalMessages(prev => [
          ...prev,
          {
            id: Date.now().toString(),
            role: 'user',
            text: transcript,
            timestamp: Date.now()
          },
          { 
            id: (Date.now() + 1).toString(),
            role: 'ai',
            text: language === 'ko'
              ? 'ì¢‹ì•„ìš”. ëŒ€í™”ë¥¼ ì¢…ë£Œí• ê²Œìš”!'
              : 'Okay, Iâ€™ll stop the conversation now.',
            timestamp: Date.now()
          }
        ]);

        await Speech.speak(
          language === 'ko'
            ? 'ì¢‹ì•„ìš”. ëŒ€í™”ë¥¼ ì¢…ë£Œí• ê²Œìš”!'
            : 'Okay, Iâ€™ll stop the conversation now.',
          {
            language,
            onDone: () => {
              handleExitWithFeedback(); // fire-and-forget
            }
          }
        );

        clearTranscript();
        return;
     }

     if (isCancelledRef.current) return;

    const userMsg: Message = {
      id: Date.now().toString(),
      role: 'user',
      text: transcript.trim(),
      timestamp: Date.now()
    };

    setLocalMessages(prev => [...prev, userMsg]);
    addMessage(topicKey, 'user', userMsg.text);
    clearTranscript();

    try {
      const reply = await fetchGptResponse(userMsg.text, {
        ignorePreviousDialogs: true,
      });

      if (!isCancelledRef.current && reply) {
        const aiMsg: Message = {
          id: Date.now().toString(),
          role: 'ai',
          text: reply,
          timestamp: Date.now()
        };

        const aiIndex = localMessages.length + 1
        setLocalMessages(prev => [...prev, aiMsg]);
        addMessage(topicKey, 'ai', aiMsg.text);

        setSpeakingIndex(aiIndex);  // AI ë§í’ì„  í•˜ì´ë¼ì´íŠ¸
        scrollToIndex(aiIndex);     // ìë™ ìŠ¤í¬ë¡¤ ì´ë™

        await Speech.speak(reply, {
          language: 'en',
          rate: 0.9,
          onDone: () => {
             setSpeakingIndex(-1); // ë§ ëë‚˜ë©´ í•˜ì´ë¼ì´íŠ¸ í•´ì œ
             startAutoRecording();
          }
        });
      }
    } catch (err) {
      console.error('Error in AI response:', err);
      const errorMsg = 'âš ï¸ Sorry, I encountered an error. Please try again.';
      setLocalMessages(prev => [
        ...prev,
        {
          id: Date.now().toString(),
          role: 'ai',
          text: errorMsg,
          timestamp: Date.now() // âœ… í•„ìˆ˜
        }
      ]);
      await Speech.speak(errorMsg, { language: 'en' });
      startAutoRecording();
    }
  };

  const handleExitWithFeedback = async () => {
     try {
       isCancelledRef.current = true;
       Speech.stop();
       stopRecording();
       setFeedbackMessage(null);
    
       if (localMessages.length > 0) {
         const feedbackItems = await generateFreeTalkFeedback(localMessages, language);

         if (feedbackItems.length > 0) {
           const feedbackData = {
             mode: 'free',
             topic: topicKey,
             sceneTitle: language === 'en' ? 'Free Talk Session'
               : language === 'ko' ? 'ììœ  ëŒ€í™” ì„¸ì…˜'
               : language === 'ja' ? 'ãƒ•ãƒªãƒ¼ãƒˆãƒ¼ã‚¯ã‚»ãƒƒì…˜'
               : 'è‡ªç”±å¯¹è¯ç¯èŠ‚',
             level: 'free',
             createdAt: new Date().toISOString(),
             items: feedbackItems,
           };

           const saveResult = await saveFeedbackToStorage(feedbackData);
           if (saveResult) {
             useFeedbackStore.getState().updateFeedbackStats(); // ë³€ê²½ëœ ìŠ¤í† ì–´ ë©”ì„œë“œ ì‚¬ìš©
             setFeedbackMessage({
               type: 'success',
               text: feedbackTranslations[language as keyof typeof feedbackTranslations]?.saved
  || feedbackTranslations.en.saved,
             });
           }
         }
       }
     } finally {
       onExitFreeTalk();
     }
  };

  const toggleRecording = () => {
    if (isRecording) {
      stopRecording();
      clearTimers();
      isCancelledRef.current = true; // ìë™ íë¦„ ì°¨ë‹¨
      Speech.stop(); // ë°œí™” ê°•ì œ ì¢…ë£Œ
    } else {
      isCancelledRef.current = false;
      startAutoRecording();
    }
  };

  return (
    <View style={freeChatStyles.container}>
      <View style={freeChatStyles.titleBox}>
        <Text style={freeChatStyles.title}>ğŸˆ Free Talking with AI</Text>
      </View>

      <FlatList
         ref={flatListRef}
         data={localMessages}
         keyExtractor={(_, index) => index.toString()}
         initialNumToRender={10}
         getItemLayout={(_, index) => ({
           length: 60, // ë§í’ì„  ëŒ€ëµ ë†’ì´ (ì‹¤ì œ ìŠ¤íƒ€ì¼ ë§ê²Œ ì¡°ì •)
           offset: 60 * index,
           index,
         })}
         renderItem={({ item, index }) => (
           <View
              style={{
                flexDirection: item.role === 'user' ? 'row-reverse' : 'row',
                paddingHorizontal: 16,
                marginVertical: 4,
              }}>
              <View
                 style={{
                   backgroundColor: item.role === 'user' ? '#d0ecff' : '#fce2eb',
                   borderRadius: 16,
                   paddingVertical: 10,
                   paddingHorizontal: 14,
                   maxWidth: '75%',
                   borderWidth: index === speakingIndex ? 2 : 0,
                   borderColor: index === speakingIndex ? '#ff5e5e' : 'transparent',
                 }}>
                 <Text style={{ fontSize: 16, flexWrap: 'wrap', flexDirection: 'row' }}>
                     {item.role === 'ai' && index === speakingIndex && currentSpeakingText.length > 0
                        ? currentSpeakingText.map((word, idx) => (
                           <Text
                               key={idx}
                               style={{
                                  backgroundColor: idx === speakingWordIndex ? '#ffe9a6' : 'transparent',
                                  fontWeight: idx === speakingWordIndex ? 'bold' : 'normal',
                               }}>
                               {word}
                           </Text>
                          ))
                     : <Text>{item.text}</Text>}
                 </Text>
              </View>
           </View>
         )}
      />

      <View style={freeChatStyles.controls}>
        <TouchableOpacity
          onPress={toggleRecording}
          style={freeChatStyles.controlButton}
        >
          <Image
            source={
              isRecording
                ? require('../assets/images/stop.png')
                : require('../assets/images/wait.png') // ë˜ëŠ” record.pngê°€ ìˆë‹¤ë©´ ì‚¬ìš©
            }
            style={{ width: 60, height: 50, resizeMode: 'contain' }}
          />
        </TouchableOpacity>

        <TouchableOpacity
          onPress={handleExitWithFeedback}
          style={freeChatStyles.controlButton}
        >
          <Image
            source={require('../assets/images/exit.png')}
            style={{ width: 60, height: 50, resizeMode: 'contain' }}
          />
        </TouchableOpacity>
      </View>
    </View>
  );
}

const freeChatStyles = StyleSheet.create({
  container: {
    flex: 1,
    paddingTop: 40,
    backgroundColor: '#fff',
  },
  titleBox: {
    backgroundColor: '#e0f5ff',
    paddingVertical: 12,
    paddingHorizontal: 24,
    marginBottom: 8,
    borderBottomWidth: 1,
    borderColor: '#cde8f7',
  },
  title: {
    fontSize: 22,
    fontWeight: 'bold',
    textAlign: 'center',
    color: '#0077cc',
  },
  controls: {
    flexDirection: 'row',
    justifyContent: 'space-around',
    alignItems: 'center',
    paddingHorizontal: 16,
    marginTop: 12,
    marginBottom: 20,
  },
  controlButton: {
    paddingVertical: 12,
    paddingHorizontal: 24,
    borderRadius: 8,
    minWidth: 100,
    alignItems: 'center',
  },
  recordButton: {
    backgroundColor: '#007bff',
  },
  stopButton: {
    backgroundColor: '#dc3545',
  },
  exitButton: {
    backgroundColor: '#6c757d',
  },
  controlButtonText: {
    color: 'white',
    fontWeight: 'bold',
    fontSize: 16,
  },
});